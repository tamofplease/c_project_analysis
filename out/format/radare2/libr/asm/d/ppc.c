# 1 "project/radare2/libr/asm/d/ppc.c"


#include <ctype.h>
#include <stdio.h>
#include <string.h>

struct kv { const char *name; const char *value; };
static struct kv kvs[] = {
  {"xxpermr","VSX Vector Permute Right-indexed"},
  {"vmrgew","Vector Merge Even Word"},
  {"vcmpnezh.","Vector Compare Not Equal or Zero Halfword"},
  {"xsrqpxp","VSX Scalar Round Quad-Precision to XP"},
  {"mtfsb1","Move To FPSCR Bit 1"},
  {"mtfsb0","Move To FPSCR Bit 0"},
  {"vctuxs","Vector Convert with round to zero FP To Unsigned Word format Saturate"},
  {"li","Load Immediate; li r3, 1; r3 = 1"},
  {"fctiwu","Floating Convert with round Double-Precision To Unsigned Word format"},
  {"bcdcfsq.","Decimal Convert From Signed Quadword & record"},
  {"bclr","Branch Conditional to LR [& Link]"},
  {"se_andc","AND with Complement Short Form"},
  {"xxlor","VSX Vector Logical OR"},
  {"ld","Load Doubleword"},
  {"vspltisw","Vector Splat Immediate Signed Word"},
  {"vmul10cuq","Vector Multiply-by-10 & write Carry Unsigned Quadword"},
  {"xssqrtqp","VSX Scalar Square Root Quad-Precision [with round to Odd]"},
  {"fre","Floating Reciprocal Estimate"},
  {"se_andi","AND Immediate Short Form"},
  {"lq","Load Quadword"},
  {"vspltisb","Vector Splat Immediate Signed Byte"},
  {"lvsr","Load Vector for Shift Right"},
  {"vrlwmi","Vector Rotate Left Word then Mask Insert"},
  {"drrndq.","DFP Reround Quad"},
  {"mtfsb1.","Move To FPSCR Bit 1"},
  {"insrwi","Insert from right immediate"},
  {"lvehx","Load Vector Element Halfword Indexed"},
  {"cntlzd","Count Leading Zeros Doubleword"},
  {"vspltish","Vector Splat Immediate Signed Halfword"},
  {"e_cmphl","Compare Halfword Logical"},
  {"ddedpd","DFP Decode DPD To BCD"},
  {"fctiw.","Floating Convert with round Double-Precision To Signed Word format"},
  {"xvtdivsp","VSX Vector Test for software Divide Single-Precision"},
  {"mtfsfi","Move To FPSCR Field Immediate"},
  {"extlwi","Extract and Left Justify Immediate"},
  {"se_bctrl","Branch to Count Register and Link"},
  {"cntlzw","Count Leading Zeros Word"},
  {"vextuhrx","Vector Extract Unsigned Halfword Right-Indexed"},
  {"dtstex","DFP Test Exponent"},
  {"# r0 "," call arg, return value"},
  {"xvmulsp","VSX Vector Multiply Single-Precision"},
  {"xvtstdcsp","VSX Vector Test Data Class Single-Precision"},
  {"mfbhrbe","Move From BHRB"},
  {"dsubq.","DFP Subtract Quad"},
  {"sthx","Store Halfword Indexed"},
  {"xvcvsxdsp","VSX Vector Convert with round Signed Doubleword to Single-Precision format"},
  {"mr","Move To Register"},
  {"fcpsgn","Floating Copy Sign"},
  {"vcmpgtsd.","Vector Compare Greater Than Signed Doubleword"},
  {"xscpsgndp","VSX Scalar Copy Sign Double-Precision"},
  {"e_crorc","Condition Register OR with Complement"},
  {"sync","Synchronize"},
  {"xsnabsqp","VSX Scalar Negative Absolute Quad-Precision"},
  {"vcmpneh.","Vector Compare Not Equal Halfword"},
  {"xscvdpsp","VSX Scalar Convert with round Double-Precision to Single-Precision format"},
  {"fmadds","Floating Multiply-Add Single"},
  {"xsnmsubasp","VSX Scalar Negative Multiply-Subtract Type-A Single-Precision"},
  {"se_lhz","Load Halfword and Zero Short Form"},
  {"se_cmp","Compare Word"},
  {"stxvll","Store VSX Vector Left-justified with Length"},
  {"bc","Branch Conditional [& Link] [Absolute]"},
  {"xvcvdpuxws","VSX Vector Convert with round to zero Double-Precision to Unsigned Word format"},
  {"sthu","Store Halfword with Update"},
  {"ba","Branch [& Link] [Absolute]"},
  {"lwax","Load Word Algebraic Indexed"},
  {"xscvqpdpo","VSX Scalar Convert with round Quad-Precision to Double-Precision format [with round to Odd]"},
  {"xvnmsubmsp","VSX Vector Negative Multiply-Subtract Type-M Single-Precision"},
  {"lwat","Load Word ATomic"},
  {"bl","Branch [& Link] [Absolute]"},
  {"stxsihx","Store VSX Scalar as Integer Halfword Indexed"},
  {"subfic","Subtract From Immediate Carrying"},
  {"hrfid","Return From Interrupt Doubleword Hypervisor"},
  {"extsw","Extend Sign Word"},
  {"xvcmpgesp","VSX Vector Compare Greater Than or Equal Single-Precision"},
  {"vcmpgefp.","Vector Compare Greater Than or Equal To Floating-Point"},
  {"vperm","Vector Permute"},
  {"bt","Branch if condition true"},
  {"mffscdrn","Move From FPSCR Control & set DRN"},
  {"dtstdg","DFP Test Data Group"},
  {"xscvdpsxds","VSX Scalar Convert with round to zero Double-Precision to Signed Doubleword format"},
  {"vextsh2w","Vector Extend Sign Halfword to Word"},
  {"mulldo","Multiply Low Doubleword"},
  {"dtstdc","DFP Test Data Class"},
  {"xsiexpdp","VSX Scalar Insert Exponent Double-Precision"},
  {"xsredp","VSX Scalar Reciprocal Estimate Double-Precision"},
  {"xsnmaddmdp","VSX Scalar Negative Multiply-Add Type-M Double-Precision"},
  {"extsh","Extend Sign Halfword"},
  {"fnmadd.","Floating Negative Multiply-Add"},
  {"dsub","DFP Subtract"},
  {"daddq.","DFP Add Quad"},
  {"extsb","Extend Sign Byte"},
  {"e_srwi","Shift Right Word Immediate"},
  {"fmadd.","Floating Multiply-Add"},
  {"mtfsf.","Move To FPSCR Fields"},
  {"divweo.","Divide Word Extended"},
  {"vextsh2d","Vector Extend Sign Halfword to Doubleword"},
  {"se_mtlr","Move To Link Register"},
  {"xvnmaddasp","VSX Vector Negative Multiply-Add Type-A Single-Precision"},
  {"bpermd","Bit Permute Doubleword"},
  {"xvcvdpsxws","VSX Vector Convert with round to zero Double-Precision to Signed Word format"},
  {"lhzx","Load Halfword & Zero Indexed"},
  {"vmhraddshs","Vector Multiply-High-Round-Add Signed Halfword Saturate"},
  {"rlwnm","Rotate Left Word then AND with Mask"},
  {"ldcix","Load Doubleword Caching Inhibited Indexed"},
  {"vaddfp","Vector Add Floating-Point"},
  {"dcffixq.","DFP Convert From Fixed Quad"},
  {"se_slw","Shift Left Word"},
  {"# r2 "," rtoc (register table of contents) (like a5 68k reg, not used, global to func (if i dont call a func))"},
  {"ddedpdq.","DFP Decode DPD To BCD Quad"},
  {"lhzu","Load Halfword & Zero with Update"},
  {"xsnmaddadp","VSX Scalar Negative Multiply-Add Type-A Double-Precision"},
  {"fmr","Floating Move Register"},
  {"xscvsxddp","VSX Scalar Convert with round Signed Doubleword to Double-Precision format"},
  {"stfiwx","Store Floating as Integer Word Indexed"},
  {"vand","Vector Logical AND"},
  {"add","Add"},
  {"mtfsb0.","Move To FPSCR Bit 0"},
  {"e_rlwi.","Rotate Left Word Immediate"},
  {"vcmpnew.","Vector Compare Not Equal Word"},
  {"nop","No Operation"},
  {"lha","Load Halfword Algebraic"},
  {"mulhwu.","Multiply High Word Unsigned"},
  {"nor","NOR"},
  {"xvnegsp","VSX Vector Negate Single-Precision"},
  {"vncipher","Vector AES Inverse Cipher"},
  {"vcmpgefp","Vector Compare Greater Than or Equal To Floating-Point"},
  {"scv","System Call Vectored"},
  {"addg6s","Add & Generate Sixes"},
  {"vrsqrtefp","Vector Reciprocal Square Root Estimate Floating-Point"},
  {"se_bl","Branch and Link"},
  {"stdcix","Store Doubleword Caching Inhibited Indexed"},
  {"e_addi.","Add Scaled Immediate"},
  {"xxmrglw","VSX Vector Merge Word Low"},
  {"lqarx","Load Quadword And Reserve Indexed"},
  {"fsel.","Floating Select"},
  {"vgbbd","Vector Gather Bits by Byte by Doubleword"},
  {"e_ori","OR Scaled Immediate"},
  {"# r1 "," stack pointer"},
  {"xsmaxdp","VSX Scalar Maximum Double-Precision"},
  {"se_bc","Branch Conditional Short Form"},
  {"divdeo.","Divide Doubleword Extended"},
  {"mulld.","Multiply Low Doubleword"},
  {"vcipher","Vector AES Cipher"},
  {"lhz","Load Halfword & Zero"},
  {"sraw.","Shift Right Algebraic Word"},
  {"fctiduz","Floating Convert with round to Zero Double-Precision To Unsigned Doubleword format"},
  {"stmw","Store Multiple Word"},
  {"xsmulqp","VSX Scalar Multiply Quad-Precision [with round to Odd]"},
  {"paste.","Paste"},
  {"vsel","Vector Select"},
  {"ori","OR Immediate"},
  {"tlbiel","TLB Invalidate Entry Local"},
  {"nand.","NAND"},
  {"fnmadds","Floating Negative Multiply-Add Single"},
  {"e_cmpli","Compare Logical Scaled Immediate Word"},
  {"crset","cR Set"},
  {"crandc","CR AND with Complement"},
  {"fsubs.","Floating Subtract Single"},
  {"xvmsubasp","VSX Vector Multiply-Subtract Type-A Single-Precision"},
  {"orc","OR with Complement"},
  {"subf","Subtract From"},
  {"vprtybw","Vector Parity Byte Word"},
  {"xsmsubmsp","VSX Scalar Multiply-Subtract Type-M Single-Precision"},
  {"dmul","DFP Multiply"},
  {"cntlzw.","Count Leading Zeros Word"},
  {"vprtybq","Vector Parity Byte Quadword"},
  {"lhzcix","Load Halfword & Zero Caching Inhibited Indexed"},
  {"lis","Load Immediate Shifted; lis r3, 0x7; r3 = 0x70000; r3 = (0x7 << 16)"},
  {"vaddsbs","Vector Add Signed Byte Saturate"},
  {"xssubdp","VSX Scalar Subtract Double-Precision"},
  {"vminsh","Vector Minimum Signed Halfword"},
  {"vprtybd","Vector Parity Byte Doubleword"},
  {"mffsce","Move From FPSCR & Clear Enables"},
  {"vminsb","Vector Minimum Signed Byte"},
  {"xsnegqp","VSX Scalar Negate Quad-Precision"},
  {"stbux","Store Byte with Update Indexed"},
  {"subfme.","Subtract From Minus One Extended"},
  {"vminsd","Vector Minimum Signed Doubleword"},
  {"cbcdtd","Convert Binary Coded Decimal To Declets"},
  {"stwu","Store Word with Update"},
  {"fctidu.","Floating Convert with round Double-Precision To Unsigned Doubleword format"},
  {"e_addic","Add Scaled Immediate Carrying"},
  {"xsrqpi","VSX Scalar Round Quad-Precision to Integral [Exact]"},
  {"mffsl","Move From FPSCR Lightweight"},
  {"vcmpeqfp.","Vector Compare Equal To Floating-Point"},
  {"xsabsdp","VSX Scalar Absolute Double-Precision"},
  {"e_crxor","Condition Register XOR"},
  {"divwo","Divide Word"},
  {"xxlorc","VSX Vector Logical OR with Complement"},
  {"xvcmpgtdp","VSX Vector Compare Greater Than Double-Precision"},
  {"drintxq.","DFP Round To FP Integer With Inexact Quad"},
  {"vclzd","Vector Count Leading Zeros Doubleword"},
  {"stwx","Store Word Indexed"},
  {"vminsw","Vector Minimum Signed Word"},
  {"vclzb","Vector Count Leading Zeros Byte"},
  {"divwe","Divide Word Extended"},
  {"xsrsqrtesp","VSX Scalar Reciprocal Square Root Estimate Single-Precision"},
  {"crclr","Conditional Register clear (xor nth bit with itself)"},
  {"xvrspi","VSX Vector Round Single-Precision to Integral"},
  {"srawi","Shift Right Algebraic Word Immediate"},
  {"xsmulsp","VSX Scalar Multiply Single-Precision"},
  {"dscri","DFP Shift Significand Right Immediate"},
  {"vsubudm","Vector Subtract Unsigned Doubleword Modulo"},
  {"vclzh","Vector Count Leading Zeros Halfword"},
  {"stwcx.","Store Word Conditional Indexed & record"},
  {"vclzw","Vector Count Leading Zeros Word"},
  {"copy","Copy"},
  {"fsub.","Floating Subtract"},
  {"or.","OR"},
  {"divwu","Divide Word Unsigned"},
  {"ddivq","DFP Divide Quad"},
  {"rlwnm.","Rotate Left Word then AND with Mask"},
  {"lxvb16x","Load VSX Vector Byte*16 Indexed"},
  {"xxpermdi","VSX Vector Doubleword Permute Immediate"},
  {"clrbhrb","Clear BHRB"},
  {"stvx","Store Vector Indexed"},
  {"slw","Shift Left Word"},
  {"mulhwu","Multiply High Word Unsigned"},
  {"vcmpgtsb.","Vector Compare Greater Than Signed Byte"},
  {"or","OR"},
  {"xscmpexpdp","VSX Scalar Compare Exponents Double-Precision"},
  {"divwo.","Divide Word"},
  {"dctfixq.","DFP Convert To Fixed Quad"},
  {"extswsli","Extend Sign Word & Shift Left Immediate"},
  {"xscvdpqp","VSX Scalar Convert Double-Precision to Quad-Precision format"},
  {"subfmeo","Subtract From Minus One Extended"},
  {"subfzeo","Subtract From Zero Extended"},
  {"sld","Shift Left Doubleword"},
  {"tw","Trap Word"},
  {"modsw","Modulo Signed Word"},
  {"vmul10euq","Vector Multiply-by-10 Extended Unsigned Quadword"},
  {"fnabs.","Floating Negative Absolute Value"},
  {"mffs.","Move From FPSCR"},
  {"dcffix.","DFP Convert From Fixed"},
  {"xxmrghw","VSX Vector Merge Word High"},
  {"e_mull2i","Multiply (2 operand) Low Immediate"},
  {"vavgsw","Vector Average Signed Word"},
  {"rlwinm.","Rotate Left Word Immediate then AND with Mask"},
  {"divw.","Divide Word"},
  {"dsub.","DFP Subtract"},
  {"modsd","Modulo Signed Doubleword"},
  {"td","Trap Doubleword"},
  {"bnelr","Branch if Not Equal to Link Register"},
  {"vavgsb","Vector Average Signed Byte"},
  {"se_isync","Instruction Synchronize"},
  {"mulhw.","Multiply High Word"},
  {"oris","OR Immediate Shifted"},
  {"vavgsh","Vector Average Signed Halfword"},
  {"xscmpeqdp","VSX Scalar Compare Equal Double-Precision"},
  {"xvmaxsp","VSX Vector Maximum Single-Precision"},
  {"eqv.","Equivalent"},
  {"clrlwi","Clear Left immediate"},
  {"divduo.","Divide Doubleword Unsigned"},
  {"vpopcntd","Vector Population Count Doubleword"},
  {"dscli.","DFP Shift Significand Left Immediate"},
  {"se_sraw","Shift Right Algebraic Word"},
  {"denbcd","DFP Encode BCD To DPD"},
  {"fdiv","Floating Divide"},
  {"e_lhzu","Load Halfword and Zero with Update"},
  {"vpopcntb","Vector Population Count Byte"},
  {"se_cmphl","Compare Halfword Logical Short Form"},
  {"lxsd","Load VSX Scalar Doubleword"},
  {"xsrsp","VSX Scalar Round Double-Precision to Single-Precision"},
  {"ddiv.","DFP Divide"},
  {"fsubs","Floating Subtract Single"},
  {"dcffixq","DFP Convert From Fixed Quad"},
  {"vmulesw","Vector Multiply Even Signed Word"},
  {"bctrl","Branch to Count Register and Link"},
  {"lmw","Load Multiple Word"},
  {"vpopcnth","Vector Population Count Halfword"},
  {"vcmpnezb.","Vector Compare Not Equal or Zero Byte"},
  {"vpopcntw","Vector Population Count Word"},
  {"slbiag","SLB Invalidate All Global"},
  {"stvxl","Store Vector Indexed Last"},
  {"vmulesb","Vector Multiply Even Signed Byte"},
  {"vmsumshm","Vector Multiply-Sum Signed Halfword Modulo"},
  {"moduw","Modulo Unsigned Word"},
  {"e_lwz","Load Word and Zero"},
  {"vmulesh","Vector Multiply Even Signed Halfword"},
  {"xsxexpqp","VSX Scalar Extract Exponent Quad-Precision"},
  {"xvcmpgtsp.","VSX Vector Compare Greater Than Single-Precision"},
  {"subfze.","Subtract From Zero Extended"},
  {"dctdp","DFP Convert To DFP Long"},
  {"sthcx.","Store Halfword Conditional Indexed & record"},
  {"vavguw","Vector Average Unsigned Word"},
  {"and","AND"},
  {"frsqrtes.","Floating Reciprocal Square Root Estimate Single"},
  {"xvcvsxwdp","VSX Vector Convert Signed Word to Double-Precision format"},
  {"vnor","Vector Logical NOR"},
  {"lbz","Load Byte & Zero"},
  {"b","Branch [& Link] [Absolute]"},
  {"dscliq","DFP Shift Significand Left Immediate Quad"},
  {"modud","Modulo Unsigned Doubleword"},
  {"lxsiwzx","Load VSX Scalar as Integer Word & Zero Indexed"},
  {"vmsumshs","Vector Multiply-Sum Signed Halfword Saturate"},
  {"lvebx","Load Vector Element Byte Indexed"},
  {"e_subfic","Subtract From Scaled Immediate Carrying"},
  {"vavgub","Vector Average Unsigned Byte"},
  {"vsubuhm","Vector Subtract Unsigned Halfword Modulo"},
  {"fnmadds.","Floating Negative Multiply-Add Single"},
  {"dsubq","DFP Subtract Quad"},
  {"lbarx","Load Byte And Reserve Indexed"},
  {"xvdivdp","VSX Vector Divide Double-Precision"},
  {"se_lwz","Load Word and Zero Short Form"},
  {"tlbie","TLB Invalidate Entry"},
  {"xvresp","VSX Vector Reciprocal Estimate Single-Precision"},
  {"vavguh","Vector Average Unsigned Halfword"},
  {"diex","DFP Insert Exponent"},
  {"fdivs.","Floating Divide Single"},
  {"stxvb16x","Store VSX Vector Byte*16 Indexed"},
  {"stxsiwx","Store VSX Scalar as Integer Word Indexed"},
  {"stxvh8x","Store VSX Vector Halfword*8 Indexed"},
  {"xvcvuxdsp","VSX Vector Convert with round Unsigned Doubleword to Single-Precision format"},
  {"vsubuhs","Vector Subtract Unsigned Halfword Saturate"},
  {"xvnmsubasp","VSX Vector Negative Multiply-Subtract Type-A Single-Precision"},
  {"addic.","Add Immediate Carrying & record"},
  {"fre.","Floating Reciprocal Estimate"},
  {"xsadddp","VSX Scalar Add Double-Precision"},
  {"vminuh","Vector Minimum Unsigned Halfword"},
  {"fmsub","Floating Multiply-Subtract"},
  {"vminud","Vector Minimum Unsigned Doubleword"},
  {"addpcis","Add PC Immediate Shifted"},
  {"e_xori","XOR Scaled Immediate"},
  {"cmp","Compare"},
  {"bcdcfz.","Decimal Convert From Zoned & record"},
  {"xvcpsgndp","VSX Vector Copy Sign Double-Precision"},
  {"mtvsrdd","Move To VSR Double Doubleword"},
  {"dtstsfi","DFP Test Significance Immediate"},
  {"vminub","Vector Minimum Unsigned Byte"},
  {"se_blrl","Branch to Link Register and Link"},
  {"vcmpgtuh.","Vector Compare Greater Than Unsigned Halfword"},
  {"se_illegal","Illegal Instruction"},
  {"dtstsfq","DFP Test Significance Quad"},
  {"slbmfev","SLB Move From Entry VSID"},
  {"maddhd","Multiply-Add High Doubleword"},
  {"vminuw","Vector Minimum Unsigned Word"},
  {"lxvl","Load VSX Vector with Length"},
  {"e_cmpl16i","Compare Logical Immediate Word"},
  {"fdivs","Floating Divide Single"},
  {"xsxsigdp","VSX Scalar Extract Significand Double-Precision"},
  {"vpkswus","Vector Pack Signed Word Unsigned Saturate"},
  {"vsubcuq","Vector Subtract & write Carry Unsigned Quadword"},
  {"slbmfee","SLB Move From Entry ESID"},
  {"drrnd","DFP Reround"},
  {"fres","Floating Reciprocal Estimate Single"},
  {"vsubcuw","Vector Subtract & Write Carry-Out Unsigned Word"},
  {"vnegw","Vector Negate Word"},
  {"xsiexpqp","VSX Scalar Insert Exponent Quad-Precision"},
  {"lxvx","Load VSX Vector Indexed"},
  {"sld.","Shift Left Doubleword"},
  {"drsp","DFP Round To DFP Short"},
  {"vabsduw","Vector Absolute Difference Unsigned Word"},
  {"xsnmaddmsp","VSX Scalar Negative Multiply-Add Type-M Single-Precision"},
  {"vpkudum","Vector Pack Unsigned Doubleword Unsigned Modulo"},
  {"lxvh8x","Load VSX Vector Halfword*8 Indexed"},
  {"se_cmpli","Compare Logical Immediate Word"},
  {"xxlnor","VSX Vector Logical NOR"},
  {"vsbox","Vector AES S-Box"},
  {"vabsdub","Vector Absolute Difference Unsigned Byte"},
  {"mullwo.","Multiply Low Word"},
  {"vmsumubm","Vector Multiply-Sum Unsigned Byte Modulo"},
  {"slbieg","SLB Invalidate Entry Global"},
  {"fctiwu.","Floating Convert with round Double-Precision To Unsigned Word format"},
  {"xxspltib","VSX Vector Splat Immediate Byte"},
  {"divwe.","Divide Word Extended"},
  {"vnegd","Vector Negate Doubleword"},
  {"xvabssp","VSX Vector Absolute Single-Precision"},
  {"vslo","Vector Shift Left by Octet"},
  {"vslh","Vector Shift Left Halfword"},
  {"vabsduh","Vector Absolute Difference Unsigned Halfword"},
  {"vsld","Vector Shift Left Doubleword"},
  {"vslb","Vector Shift Left Byte"},
  {"vsl","Vector Shift Left"},
  {"tend.","Transaction End & record"},
  {"drintnq","DFP Round To FP Integer Without Inexact Quad"},
  {"vpkudus","Vector Pack Unsigned Doubleword Unsigned Saturate"},
  {"vcmpnezw","Vector Compare Not Equal or Zero Word"},
  {"lfd","Load Floating Double"},
  {"vnmsubfp","Vector Negative Multiply-Subtract Floating-Point"},
  {"vsr","Vector Shift Right"},
  {"xvmsubmsp","VSX Vector Multiply-Subtract Type-M Single-Precision"},
  {"lfdx","Load Floating Double Indexed"},
  {"lxvd2x","Load VSX Vector Doubleword*2 Indexed"},
  {"addze","Add to Zero Extended"},
  {"mfvsrwz","Move From VSR Word & Zero"},
  {"xsrdpi","VSX Scalar Round Double-Precision to Integral"},
  {"vslv","Vector Shift Left Variable"},
  {"vslw","Vector Shift Left Word"},
  {"xsnabsdp","VSX Scalar Negative Absolute Double-Precision"},
  {"stxsdx","Store VSX Scalar Doubleword Indexed"},
  {"vcmpnezh","Vector Compare Not Equal or Zero Halfword"},
  {"dcbtst","Data Cache Block Touch for Store"},
  {"lfdp","Load Floating Double Pair"},
  {"cp_abort","CP_Abort"},
  {"e_crandc","Condition Register AND with Complement"},
  {"se_extsb","Extend Sign Byte Short Form"},
  {"se_bgeni","Bit Generate Immediate"},
  {"fctid.","Floating Convert with round Double-Precision To Signed Doubleword format"},
  {"lfdu","Load Floating Double with Update"},
  {"addeo.","Add Extended"},
  {"lfs","Load Floating Single"},
  {"vpkswss","Vector Pack Signed Word Signed Saturate"},
  {"vcmpnezb","Vector Compare Not Equal or Zero Byte"},
  {"xvcvuxwdp","VSX Vector Convert Unsigned Word to Double-Precision format"},
  {"dcbf","Data Cache Block Flush"},
  {"fdiv.","Floating Divide"},
  {"treclaim.","Transaction Reclaim & record"},
  {"se_extsh","Extend Sign Halfword Short Form"},
  {"fnmsub.","Floating Negative Multiply-Subtract"},
  {"drintn.","DFP Round To FP Integer Without Inexact"},
  {"xvnabssp","VSX Vector Negative Absolute Single-Precision"},
  {"mflr","Move From Link Register"},
  {"fctiwuz","Floating Convert with round to Zero Double-Precision To Unsigned Word format"},
  {"dcbt","Data Cache Block Touch"},
  {"dcbz","Data Cache Block Zero"},
  {"xsnmsubmsp","VSX Scalar Negative Multiply-Subtract Type-M Single-Precision"},
  {"divweo","Divide Word Extended"},
  {"vsubuws","Vector Subtract Unsigned Word Saturate"},
  {"fmul","Floating Multiply"},
  {"lbzcix","Load Byte & Zero Caching Inhibited Indexed"},
  {"vcmpequh.","Vector Compare Equal To Unsigned Halfword"},
  {"vsrv","Vector Shift Right Variable"},
  {"vsrw","Vector Shift Right Word"},
  {"dcffix","DFP Convert From Fixed"},
  {"vaddshs","Vector Add Signed Halfword Saturate"},
  {"creqv","CR Equivalent"},
  {"mtocrf","Move To One CR Field"},
  {"drintnq.","DFP Round To FP Integer Without Inexact Quad"},
  {"xssubqp","VSX Scalar Subtract Quad-Precision [with round to Odd]"},
  {"fctidz","Floating Convert with round to Zero Double-Precision To Signed Doubleword format"},
  {"xsnmaddqp","VSX Scalar Negative Multiply-Add Quad-Precision [with round to Odd]"},
  {"mtspr","Move To SPR"},
  {"isel","Integer Select"},
  {"vsrb","Vector Shift Right Byte"},
  {"vsubuwm","Vector Subtract Unsigned Word Modulo"},
  {"vsrd","Vector Shift Right Doubleword"},
  {"e_b","Branch"},
  {"xvcpsgnsp","VSX Vector Copy Sign Single-Precision"},
  {"fctidu","Floating Convert with round Double-Precision To Unsigned Doubleword format"},
  {"maddld","Multiply-Add Low Doubleword"},
  {"divweu","Divide Word Extended Unsigned"},
  {"se_b","Branch"},
  {"frsqrtes","Floating Reciprocal Square Root Estimate Single"},
  {"vsrh","Vector Shift Right Halfword"},
  {"popcntw","Population Count Words"},
  {"se_bclri","Bit Clear Immediate"},
  {"vsro","Vector Shift Right by Octet"},
  {"prtyd","Parity Doubleword"},
  {"se_rfmci","Return From Machine Check Interrupt"},
  {"ldx","Load Doubleword Indexed"},
  {"vpkuwus","Vector Pack Unsigned Word Unsigned Saturate"},
  {"fmr.","Floating Move Register"},
  {"xsrqpix","VSX Scalar Round Quad-Precision to Integral [Exact]"},
  {"ldu","Load Doubleword with Update"},
  {"xsmsubqp","VSX Scalar Multiply-Subtract Quad-Precision [with round to Odd]"},
  {"isync","Instruction Synchronize"},
  {"veqv","Vector Equivalence"},
  {"vpkuwum","Vector Pack Unsigned Word Unsigned Modulo"},
  {"xvnmaddmsp","VSX Vector Negative Multiply-Add Type-M Single-Precision"},
  {"popcntb","Population Count Byte"},
  {"friz","Floating Round To Integer Zero"},
  {"dqua","DFP Quantize"},
  {"prtyw","Parity Word"},
  {"dctqpq","DFP Convert To DFP Extended"},
  {"fadds.","Floating Add Single"},
  {"popcntd","Population Count Doubleword"},
  {"rldicl.","Rotate Left Doubleword Immediate then Clear Left"},
  {"mulhw","Multiply High Word"},
  {"frip","Floating Round To Integer Plus"},
  {"bge","Branch if Greater Or Equal"},
  {"cnttzw.","Count Trailing Zeros Word"},
  {"xvredp","VSX Vector Reciprocal Estimate Double-Precision"},
  {"vcmpgtsw.","Vector Compare Greater Than Signed Word"},
  {"xscmpgtdp","VSX Scalar Compare Greater Than Double-Precision"},
  {"orc.","OR with Complement"},
  {"inslwi","Insert from left immediate"},
  {"xscvuxddp","VSX Scalar Convert with round Unsigned Doubleword to Double-Precision format"},
  {"vcmpgtsh","Vector Compare Greater Than Signed Halfword"},
  {"fnmsubs","Floating Negative Multiply-Subtract Single"},
  {"dxex","DFP Extract Exponent"},
  {"stwux","Store Word with Update Indexed"},
  {"mfvscr","Move From VSCR"},
  {"rlwimi","Rotate Left Word Immediate then Mask Insert"},
  {"stxv","Store VSX Vector"},
  {"frim","Floating Round To Integer Minus"},
  {"mulhd","Multiply High Doubleword"},
  {"frin","Floating Round To Integer Nearest"},
  {"neg","Negate"},
  {"vcmpgtsd","Vector Compare Greater Than Signed Doubleword"},
  {"xsmaddadp","VSX Scalar Multiply-Add Type-A Double-Precision"},
  {"frsqrte","Floating Reciprocal Square Root Estimate"},
  {"vcfux","Vector Convert with round to nearest Unsigned Word format to FP"},
  {"bgt","Branch if Greater Than"},
  {"ddedpd.","DFP Decode DPD To BCD"},
  {"xscmpudp","VSX Scalar Compare Unordered Double-Precision"},
  {"stwbrx","Store Word Byte-Reverse Indexed"},
  {"maddhdu","Multiply-Add High Doubleword Unsigned"},
  {"crnot","CR NOT"},
  {"xsnmsubqpo","VSX Scalar Negative Multiply-Subtract Quad-Precision [with round to Odd]"},
  {"vcmpgtsb","Vector Compare Greater Than Signed Byte"},
  {"bcdadd.","Decimal Add Modulo & record"},
  {"bcdtrunc.","Decimal Truncate & record"},
  {"vmhaddshs","Vector Multiply-High-Add Signed Halfword Saturate"},
  {"e_rlwimi","Rotate Left Word Immediate then Mask Insert"},
  {"crnor","CR NOR"},
  {"fcfids.","Floating Convert with round Signed Doubleword to Single-Precision format"},
  {"xssubsp","VSX Scalar Subtract Single-Precision"},
  {"vcmpgtub.","Vector Compare Greater Than Unsigned Byte"},
  {"xvmuldp","VSX Vector Multiply Double-Precision"},
  {"dcbst","Data Cache Block Store"},
  {"vcmpgtsw","Vector Compare Greater Than Signed Word"},
  {"xvtstdcdp","VSX Vector Test Data Class Double-Precision"},
  {"bctar","Branch Conditional to BTAR [& Link]"},
  {"dscriq.","DFP Shift Significand Right Immediate Quad"},
  {"lxsihzx","Load VSX Scalar as Integer Halfword & Zero Indexed"},
  {"xsminjdp","VSX Scalar Minimum Type-J Double-Precision"},
  {"xvrsqrtesp","VSX Vector Reciprocal Square Root Estimate Single-Precision"},
  {"xsmaddmdp","VSX Scalar Multiply-Add Type-M Double-Precision"},
  {"vsubuqm","Vector Subtract Unsigned Quadword Modulo"},
  {"cror","CR OR"},
  {"vmaxfp","Vector Maximum Floating-Point"},
  {"mfspr","Move From SPR"},
  {"ddedpdq","DFP Decode DPD To BCD Quad"},
  {"xsmsubasp","VSX Scalar Multiply-Subtract Type-A Single-Precision"},
  {"xvcmpgedp","VSX Vector Compare Greater Than or Equal Double-Precision"},
  {"se_srwi","Shift Right Word Immediate Short Form"},
  {"e_rlwinm","Rotate Left Word Immediate then AND with Mask,"},
  {"mtmsr","Move To MSR"},
  {"xsrsqrtedp","VSX Scalar Reciprocal Square Root Estimate Double-Precision"},
  {"fneg","Floating Negate"},
  {"addzeo","Add to Zero Extended"},
  {"vmuleuw","Vector Multiply Even Unsigned Word"},
  {"bclrl","Branch Conditional to LR [& Link]"},
  {"stfdp","Store Floating Double Pair"},
  {"frsqrte.","Floating Reciprocal Square Root Estimate"},
  {"vpkuhum","Vector Pack Unsigned Halfword Unsigned Modulo"},
  {"vcmpgtuh","Vector Compare Greater Than Unsigned Halfword"},
  {"vmsumudm","Vector Multiply-Sum Unsigned Doubleword Modulo"},
  {"stfdu","Store Floating Double with Update"},
  {"friz.","Floating Round To Integer Zero"},
  {"dquai","DFP Quantize Immediate"},
  {"stfdx","Store Floating Double Indexed"},
  {"vpkuhus","Vector Pack Unsigned Halfword Unsigned Saturate"},
  {"sc","System Call"},
  {"vcmpgtub","Vector Compare Greater Than Unsigned Byte"},
  {"xvnabsdp","VSX Vector Negative Absolute Double-Precision"},
  {"crxor","Conditional Register bit XOR"},
  {"vcmpequd.","Vector Compare Equal To Unsigned Doubleword"},
  {"subfze","Subtract From Zero Extended"},
  {"dquaq","DFP Quantize Quad"},
  {"vcmpgtud","Vector Compare Greater Than Unsigned Doubleword"},
  {"mtvsrd","Move To VSR Doubleword"},
  {"vmuleub","Vector Multiply Even Unsigned Byte"},
  {"xvtsqrtdp","VSX Vector Test for software Square Root Double-Precision"},
  {"se_sc","System Call"},
  {"lxv","Load VSX Vector"},
  {"vcmpgtuw","Vector Compare Greater Than Unsigned Word"},
  {"vmuleuh","Vector Multiply Even Unsigned Halfword"},
  {"e_cmph16i","Compare Halfword Immediate"},
  {"dtstdgq","DFP Test Data Group Quad"},
  {"e_lbz","Load Byte and Zero"},
  {"divweuo.","Divide Word Extended Unsigned"},
  {"vmul10uq","Vector Multiply-by-10 Unsigned Quadword"},
  {"se_mtctr","Move To Count Register"},
  {"xvrdpic","VSX Vector Round Double-Precision to Integral using Current rounding mode"},
  {"fcpsgn.","Floating Copy Sign"},
  {"se_and","AND Short Form"},
  {"xvrdpim","VSX Vector Round Double-Precision to Integral toward -Infinity"},
  {"dctfix","DFP Convert To Fixed"},
  {"bcdctz.","Decimal Convert To Zoned & record"},
  {"vupkhpx","Vector Unpack High Pixel"},
  {"mullw","Multiply Low Word"},
  {"srawi.","Shift Right Algebraic Word Immediate"},
  {"dscri.","DFP Shift Significand Right Immediate"},
  {"vcmpequh","Vector Compare Equal To Unsigned Halfword"},
  {"addze.","Add to Zero Extended"},
  {"xvrdpip","VSX Vector Round Double-Precision to Integral toward +Infinity"},
  {"bca","Branch Conditional [& Link] [Absolute]"},
  {"vcmpequd","Vector Compare Equal To Unsigned Doubleword"},
  {"tabortdc.","Transaction Abort Doubleword Conditional & record"},
  {"e_lbzu","Load Byte and Zero with Update"},
  {"bcl","Branch Conditional [& Link] [Absolute]"},
  {"mulli","Multiply Low Immediate"},
  {"fcfid","Floating Convert with round Signed Doubleword to Double-Precision format"},
  {"vcmpequb","Vector Compare Equal To Unsigned Byte"},
  {"dqua.","DFP Quantize"},
  {"mulld","Multiply Low Doubleword"},
  {"xvrdpiz","VSX Vector Round Double-Precision to Integral toward Zero"},
  {"vcmpbfp.","Vector Compare Bounds Floating-Point"},
  {"subfco.","Subtract From Carrying"},
  {"vrldnm","Vector Rotate Left Doubleword then AND with Mask"},
  {"fcfidus","Floating Convert with round Unsigned Doubleword to Single-Precision format"},
  {"andi.","AND Immediate & record"},
  {"se_extzh","Extend Zero Halfword"},
  {"vcmpequw","Vector Compare Equal To Unsigned Word"},
  {"xvadddp","VSX Vector Add Double-Precision"},
  {"xscvudqp","VSX Scalar Convert Unsigned Doubleword to Quad-Precision format"},
  {"twi","Trap Word Immediate"},
  {"slbsync","SLB Synchronize"},
  {"cmplwi","Compare Logical Word Immediate; cmplwi CR0, r0, 33(unsigned)"},
  {"e_sc","System Call"},
  {"lxsdx","Load VSX Scalar Doubleword Indexed"},
  {"se_extzb","Extend Zero Byte"},
  {"adde","Add Extended"},
  {"vsubecuq","Vector Subtract Extended & write Carry Unsigned Quadword"},
  {"addc","Add Carrying"},
  {"drintn","DFP Round To FP Integer Without Inexact"},
  {"addo","Add"},
  {"xvcvsxddp","VSX Vector Convert with round Signed Doubleword to Double-Precision format"},
  {"addi","Add Immediate"},
  {"xsnmaddasp","VSX Scalar Negative Multiply-Add Type-A Single-Precision"},
  {"msgclr","Message Clear"},
  {"xscpsgnqp","VSX Scalar Copy Sign Quad-Precision"},
  {"xvmindp","VSX Vector Minimum Double-Precision"},
  {"drintx","DFP Round To FP Integer With Inexact"},
  {"bcdctsq.","Decimal Convert To Signed Quadword & record"},
  {"xvcvsxwsp","VSX Vector Convert with round Signed Word to Single-Precision format"},
  {"e_subfic.","Subtract From Scaled Immediate Carrying"},
  {"dctfix.","DFP Convert To Fixed"},
  {"rlwinm","Rotate Left Word Immediate then AND with Mask"},
  {"tbegin.","Transaction Begin & record"},
  {"stdat","Store Doubleword ATomic"},
  {"bdz","Decrement CTR and Branch if its Zero"},
  {"lxsspx","Load VSX Scalar Single-Precision Indexed"},
  {"bcdsub.","Decimal Subtract Modulo & record"},
  {"mtvsrwz","Move To VSR Word & Zero"},
  {"mffscdrni","Move From FPSCR Control & set DRN Immediate"},
  {"mtcrf","Move To CR Fields"},
  {"xscvdpsxws","VSX Scalar Convert with round to zero Double-Precision to Signed Word format"},
  {"xvrdpi","VSX Vector Round Double-Precision to Integral"},
  {"extswsli.","Extend Sign Word & Shift Left Immediate"},
  {"fnabs","Floating Negative Absolute Value"},
  {"mtvsrws","Move To VSR Word & Splat"},
  {"e_li","Load Immediate; e_li r3, 1; r3 = 1"},
  {"dcmpuq","DFP Compare Unordered Quad"},
  {"vmaddfp","Vector Multiply-Add Floating-Point"},
  {"vmsumuhm","Vector Multiply-Sum Unsigned Halfword Modulo"},
  {"fsqrts.","Floating Square Root Single"},
  {"xscvspdp","VSX Scalar Convert Single-Precision to Double-Precision format"},
  {"mfvsrld","Move From VSR Lower Doubleword"},
  {"lfiwzx","Load Floating as Integer Word & Zero Indexed"},
  {"denbcdq.","DFP Encode BCD To DPD Quad"},
  {"lwzu","Load Word & Zero with Update"},
  {"e_cror","Condition Register OR"},
  {"vaddubm","Vector Add Unsigned Byte Modulo"},
  {"srd.","Shift Right Doubleword"},
  {"fmsubs.","Floating Multiply-Subtract Single"},
  {"stvewx","Store Vector Element Word Indexed"},
  {"drrnd.","DFP Reround"},
  {"mtvsrwa","Move To VSR Word Algebraic"},
  {"beq","Branch if Equal bne=Branch if Not Equal"},
  {"xscvqpsdz","VSX Scalar Convert with round to zero Quad-Precision to Signed Doubleword format"},
  {"vcfsx","Vector Convert with round to nearest Signed Word format to FP"},
  {"lwzx","Load Word & Zero Indexed"},
  {"fcfidu.","Floating Convert with round Unsigned Doubleword to Double-Precision format"},
  {"vcmpgtud.","Vector Compare Greater Than Unsigned Doubleword"},
  {"dscriq","DFP Shift Significand Right Immediate Quad"},
  {"vaddubs","Vector Add Unsigned Byte Saturate"},
  {"vlogefp","Vector Log Base 2 Estimate Floating-Point"},
  {"xsmaddasp","VSX Scalar Multiply-Add Type-A Single-Precision"},
  {"e_cmp16i","Compare Immediate Word"},
  {"rldic","Rotate Left Doubleword Immediate then Clear"},
  {"mtlr","Move To Link Register"},
  {"mulhdu","Multiply High Doubleword Unsigned"},
  {"vmsumuhs","Vector Multiply-Sum Unsigned Halfword Saturate"},
  {"e_mulli","Multiply Low Scaled Immediate"},
  {"lharx","Load Halfword And Reserve Indexed Xform"},
  {"bnl","Branch if Not Less"},
  {"add.","Add"},
  {"vsldoi","Vector Shift Left Double by Octet Immediate"},
  {"xsmaddqp","VSX Scalar Multiply-Add Quad-Precision [with round to Odd]"},
  {"slbfee.","SLB Find Entry ESID & record"},
  {"rldimi.","Rotate Left Doubleword Immediate then Mask Insert"},
  {"slbmte","SLB Move To Entry"},
  {"dtstdcq","DFP Test Data Class Quad"},
  {"extsw.","Extend Sign Word"},
  {"fsqrts","Floating Square Root Single"},
  {"xvcvspsxws","VSX Vector Convert with round to zero Single-Precision to Signed Word format"},
  {"vmul10ecuq","Vector Multiply-by-10 Extended & write Carry Unsigned Quadword"},
  {"dctfixq","DFP Convert To Fixed Quad"},
  {"vrldmi","Vector Rotate Left Doubleword then Mask Insert"},
  {"fnmsubs.","Floating Negative Multiply-Subtract Single"},
  {"lhau","Load Halfword Algebraic with Update"},
  {"lhax","Load Halfword Algebraic Indexed"},
  {"bcdus.","Decimal Unsigned Shift & record"},
  {"crorc","CR OR with Complement"},
  {"xsxsigqp","VSX Scalar Extract Significand Quad-Precision"},
  {"xscmpoqp","VSX Scalar Compare Ordered Quad-Precision"},
  {"divduo","Divide Doubleword Unsigned"},
  {"stxssp","Store VSX Scalar Single-Precision"},
  {"dtstsf","DFP Test Significance"},
  {"frip.","Floating Round To Integer Plus"},
  {"stdcx.","Store Doubleword Conditional Indexed & record"},
  {"mtmsrd","Move To MSR Doubleword"},
  {"ldarx","Load Doubleword And Reserve Indexed"},
  {"lxvll","Load VSX Vector Left-justified with Length"},
  {"divweu.","Divide Word Extended Unsigned"},
  {"mtctr","Move To Special Count Register"},
  {"vcmpequb.","Vector Compare Equal To Unsigned Byte"},
  {"xvmaxdp","VSX Vector Maximum Double-Precision"},
  {"icbi","Instruction Cache Block Invalidate"},
  {"xsmuldp","VSX Scalar Multiply Double-Precision"},
  {"vaddudm","Vector Add Unsigned Doubleword Modulo"},
  {"mffs","Move From FPSCR"},
  {"xvmaddmdp","VSX Vector Multiply-Add Type-M Double-Precision"},
  {"divw","Divide Word"},
  {"rldcr","Rotate Left Doubleword then Clear Right"},
  {"fabs.","Floating Absolute"},
  {"rldcl","Rotate Left Doubleword then Clear Left"},
  {"xvcvspuxws","VSX Vector Convert with round to zero Single-Precision to Unsigned Word format"},
  {"vrefp","Vector Reciprocal Estimate Floating-Point"},
  {"vsum4ubs","Vector Sum across Quarter Unsigned Byte Saturate"},
  {"mtfsf","Move To FPSCR Fields"},
  {"fmadd","Floating Multiply-Add"},
  {"drintx.","DFP Round To FP Integer With Inexact"},
  {"e_lwzu","Load Word and Zero with Update"},
  {"lfiwax","Load Floating as Integer Word Algebraic Indexed"},
  {"ftsqrt","Floating Test for software Square Root"},
  {"e_lhz","Load Halfword and Zero"},
  {"fsqrt.","Floating Square Root"},
  {"e_addic.","Add Scaled Immediate Carrying"},
  {"icbt","Instruction Cache Block Touch"},
  {"vaddsws","Vector Add Signed Word Saturate"},
  {"divd","Divide Doubleword"},
  {"e_and2i","AND (two operand) Immediate"},
  {"drrndq","DFP Reround Quad"},
  {"xsaddsp","VSX Scalar Add Single-Precision"},
  {"nor.","NOR"},
  {"mulhd.","Multiply High Doubleword"},
  {"frsp.","Floating Round to Single-Precision"},
  {"vmuluwm","Vector Multiply Unsigned Word Modulo"},
  {"xvsubdp","VSX Vector Subtract Double-Precision"},
  {"xvtdivdp","VSX Vector Test for software Divide Double-Precision"},
  {"dquaiq.","DFP Quantize Immediate Quad"},
  {"ftdiv","Floating Test for software Divide"},
  {"se_cmph","Compare Halfword Short Form"},
  {"se_cmpi","Compare Immediate Word Short Form"},
  {"lwbrx","Load Word Byte-Reverse Indexed"},
  {"xsdivqp","VSX Scalar Divide Quad-Precision [with round to Odd]"},
  {"se_cmpl","Compare Logical Word"},
  {"lxsiwax","Load VSX Scalar as Integer Word Algebraic Indexed"},
  {"e_lha","Load Halfword Algebraic"},
  {"divdu.","Divide Doubleword Unsigned"},
  {"xvcmpgtsp","VSX Vector Compare Greater Than Single-Precision"},
  {"fsub","Floating Subtract"},
  {"vexptefp","Vector 2 Raised to the Exponent Estimate Floating-Point"},
  {"e_xori.","XOR Scaled Immediate"},
  {"se_mullw","Multiply Low Word Short Form"},
  {"diex.","DFP Insert Exponent"},
  {"vupkhsb","Vector Unpack High Signed Byte"},
  {"se_slwi","Shift Left Word Immediate Short Form"},
  {"addme.","Add to Minus One Extended"},
  {"e_lis","Load Immediate Shifted; e_lis r3, 0x7; r3 = 0x70000; r3 = (0x7 << 16)"},
  {"xsmulqpo","VSX Scalar Multiply Quad-Precision [with round to Odd]"},
  {"divweuo","Divide Word Extended Unsigned"},
  {"vextubrx","Vector Extract Unsigned Byte Right-Indexed"},
  {"vupkhsh","Vector Unpack High Signed Halfword"},
  {"lxvdsx","Load VSX Vector Doubleword & Splat Indexed"},
  {"crand","CR AND"},
  {"andc.","AND with Complement"},
  {"drintxq","DFP Round To FP Integer With Inexact Quad"},
  {"vupkhsw","Vector Unpack High Signed Word"},
  {"e_creqv","Condition Register Equivalent"},
  {"neg.","Negate"},
  {"xvcvuxddp","VSX Vector Convert with round Unsigned Doubleword to Double-Precision format"},
  {"xvcmpeqdp","VSX Vector Compare Equal Double-Precision"},
  {"divd.","Divide Doubleword"},
  {"tabortwc.","Transaction Abort Word Conditional & record"},
  {"fmadds.","Floating Multiply-Add Single"},
  {"msgsndp","Message Send Privileged"},
  {"dctdp.","DFP Convert To DFP Long"},
  {"srad","Shift Right Algebraic Doubleword"},
  {"xsmincdp","VSX Scalar Minimum Type-C Double-Precision"},
  {"divdeuo.","Divide Doubleword Extended Unsigned"},
  {"stwcix","Store Word Caching Inhibited Indexed"},
  {"vncipherlast","Vector AES Inverse Cipher Last"},
  {"diexq","DFP Insert Exponent Quad"},
  {"xststdcqp","VSX Scalar Test Data Class Quad-Precision"},
  {"sraw","Shift Right Algebraic Word"},
  {"e_crand","Condition Register AND"},
  {"xscvdpuxds","VSX Scalar Convert with round to zero Double-Precision to Unsigned Doubleword format"},
  {"xsxexpdp","VSX Scalar Extract Exponent Double-Precision"},
  {"sthux","Store Halfword with Update Indexed"},
  {"lxsibzx","Load VSX Scalar as Integer Byte & Zero Indexed"},
  {"e_andi","AND Scaled Immediate"},
  {"mfcr","Move From CR"},
  {"xxbrw","VSX Vector Byte-Reverse Word"},
  {"xsmaxjdp","VSX Scalar Maximum Type-J Double-Precision"},
  {"xxbrq","VSX Vector Byte-Reverse Quadword"},
  {"paste","Paste"},
  {"dscli","DFP Shift Significand Left Immediate"},
  {"e_or2is","OR (2 operand) Immediate Shifted"},
  {"vpermr","Vector Permute Right-indexed"},
  {"e_stwu","Store Word with Update"},
  {"drdpq.","DFP Round To DFP Long"},
  {"xvcmpgtdp.","VSX Vector Compare Greater Than Double-Precision"},
  {"lhaux","Load Halfword Algebraic with Update Indexed"},
  {"xxbrd","VSX Vector Byte-Reverse Doubleword"},
  {"ddivq.","DFP Divide Quad"},
  {"msgsync","Message Synchronize"},
  {"addmeo","Add to Minus One Extended"},
  {"dscliq.","DFP Shift Significand Left Immediate Quad"},
  {"fctiwuz.","Floating Convert with round to Zero Double-Precision To Unsigned Word format"},
  {"msgsnd","Message Send"},
  {"nego","Negate"},
  {"fmuls.","Floating Multiply Single"},
  {"stbcix","Store Byte Caching Inhibited Indexed"},
  {"divdu","Divide Doubleword Unsigned"},
  {"xxbrh","VSX Vector Byte-Reverse Halfword"},
  {"se_rfdi","Return From Debug Interrupt"},
  {"lwzux","Load Word & Zero with Update Indexed"},
  {"divdo","Divide Doubleword"},
  {"mfocrf","Move From One CR Field"},
  {"xvmaddmsp","VSX Vector Multiply-Add Type-M Single-Precision"},
  {"mffscrni","Move From FPSCR Control & set RN Immediate"},
  {"xviexpdp","VSX Vector Insert Exponent Double-Precision"},
  {"xor","XOR"},
  {"lvx","Load Vector Indexed"},
  {"divwu.","Divide Word Unsigned"},
  {"divde","Divide Doubleword Extended"},
  {"bla","Branch [& Link] [Absolute]"},
  {"fctiw","Floating Convert with round Double-Precision To Signed Word format"},
  {"xststdcsp","VSX Scalar Test Data Class Single-Precision"},
  {"vshasigmaw","Vector SHA-256 Sigma Word"},
  {"ble","Branch if Less or Equal"},
  {"vcmpgtfp.","Vector Compare Greater Than Floating-Point"},
  {"vcmpgtfp","Vector Compare Greater Than Floating-Point"},
  {"se_rfci","Return From Critical Interrupt"},
  {"slbia","SLB Invalidate All"},
  {"e_add2i.","Add (2 operand) Immediate and Record"},
  {"xvcvdpsxds","VSX Vector Convert with round to zero Double-Precision to Signed Doubleword format"},
  {"andc","AND with Complement"},
  {"slbie","SLB Invalidate Entry"},
  {"blr","Branch to Link Register"},
  {"dadd","DFP Add"},
  {"vshasigmad","Vector SHA-512 Sigma Doubleword"},
  {"fctid","Floating Convert with round Double-Precision To Signed Doubleword format"},
  {"xsmsubqpo","VSX Scalar Multiply-Subtract Quad-Precision [with round to Odd]"},
  {"se_add","Add Short Form"},
  {"xvmaddadp","VSX Vector Multiply-Add Type-A Double-Precision"},
  {"blt","Branch if Less"},
  {"srd","Shift Right Doubleword"},
  {"lwz","Load Word And Zero"},
  {"vmaxsw","Vector Maximum Signed Word"},
  {"vmsummbm","Vector Multiply-Sum Mixed Byte Modulo"},
  {"e_lmw","Load Multiple Word"},
  {"dadd.","DFP Add"},
  {"fnmadd","Floating Negative Multiply-Add"},
  {"vsumsws","Vector Sum across Signed Word Saturate"},
  {"vmaxsd","Vector Maximum Signed Doubleword"},
  {"srw","Shift Right Word"},
  {"vrlh","Vector Rotate Left Halfword"},
  {"vmaxsb","Vector Maximum Signed Byte"},
  {"vrld","Vector Rotate Left Doubleword"},
  {"lwa","Load Word Algebraic"},
  {"vmaxsh","Vector Maximum Signed Halfword"},
  {"vrlb","Vector Rotate Left Byte"},
  {"xsresp","VSX Scalar Reciprocal Estimate Single-Precision"},
  {"e_lhau","Load Halfword Algebraic with Update"},
  {"stfdpx","Store Floating Double Pair Indexed"},
  {"divwuo","Divide Word Unsigned"},
  {"mcrxrx","Move XER to CR Extended"},
  {"fctiduz.","Floating Convert with round to Zero Double-Precision To Unsigned Doubleword format"},
  {"xsaddqp","VSX Scalar Add Quad-Precision [with round to Odd]"},
  {"and.","AND"},
  {"vrlw","Vector Rotate Left Word"},
  {"vextractuh","Vector Extract Unsigned Halfword"},
  {"dcmpoq","DFP Compare Ordered Quad"},
  {"bcdcpsgn.","Decimal CopySign & record"},
  {"mfvsrd","Move From VSR Doubleword"},
  {"vextractub","Vector Extract Unsigned Byte"},
  {"cnttzd.","Count Trailing Zeros Doubleword"},
  {"lxvwsx","Load VSX Vector Word & Splat Indexed"},
  {"xsdivsp","VSX Scalar Divide Single-Precision"},
  {"tabortwci.","Transaction Abort Word Conditional Immediate & record"},
  {"xvcmpeqdp.","VSX Vector Compare Equal Double-Precision"},
  {"mtctrl","Move To Special Count Register and Link"},
  {"xvminsp","VSX Vector Minimum Single-Precision"},
  {"xvrsqrtedp","VSX Vector Reciprocal Square Root Estimate Double-Precision"},
  {"vsum2sws","Vector Sum across Half Signed Word Saturate"},
  {"fmul.","Floating Multiply"},
  {"vaddeuqm","Vector Add Extended Unsigned Quadword Modulo"},
  {"xsmaddmsp","VSX Scalar Multiply-Add Type-M Single-Precision"},
  {"e_add2is","Add (2 operand) Immediate Shifted"},
  {"stb","Store Byte"},
  {"vminfp","Vector Minimum Floating-Point"},
  {"sradi","Shift Right Algebraic Doubleword Immediate"},
  {"xscvdphp","VSX Scalar Convert with round Double-Precision to Half-Precision format"},
  {"e_slwi.","Shift Left Word Immediate"},
  {"vextractuw","Vector Extract Unsigned Word"},
  {"std","Store Doubleword"},
  {"e_andi.","AND Scaled Immediate"},
  {"xsaddqpo","VSX Scalar Add Quad-Precision [with round to Odd]"},
  {"vmaxuw","Vector Maximum Unsigned Word"},
  {"diexq.","DFP Insert Exponent Quad"},
  {"se_mfar","Move from Alternate Register"},
  {"sth","Store Halfword"},
  {"daddq","DFP Add Quad"},
  {"bcdctn.","Decimal Convert To National & record"},
  {"addmeo.","Add to Minus One Extended"},
  {"mffscrn","Move From FPSCR Control & set RN"},
  {"xscvsdqp","VSX Scalar Convert Signed Doubleword to Quad-Precision format"},
  {"vaddcuw","Vector Add & Write Carry-Out Unsigned Word"},
  {"vmaxub","Vector Maximum Unsigned Byte"},
  {"stq","Store Quadword"},
  {"vaddcuq","Vector Add & write Carry Unsigned Quadword"},
  {"ldat","Load Doubleword ATomic"},
  {"stw","Store Word"},
  {"vmaxud","Vector Maximum Unsigned Doubleword"},
  {"xvrspip","VSX Vector Round Single-Precision to Integral toward +Infinity"},
  {"xxspltw","VSX Vector Splat Word"},
  {"divdo.","Divide Doubleword"},
  {"vmaxuh","Vector Maximum Unsigned Halfword"},
  {"lxssp","Load VSX Scalar Single"},
  {"xvrspiz","VSX Vector Round Single-Precision to Integral toward Zero"},
  {"vxor","Vector Logical XOR"},
  {"xsmaxcdp","VSX Scalar Maximum Type-C Double-Precision"},
  {"xvsqrtdp","VSX Vector Square Root Double-Precision"},
  {"dtstexq","DFP Test Exponent Quad"},
  {"xvaddsp","VSX Vector Add Single-Precision"},
  {"xvrspic","VSX Vector Round Single-Precision to Integral using Current rounding mode"},
  {"bcdsr.","Decimal Shift & Round & record"},
  {"fmuls","Floating Multiply Single"},
  {"vcmpeqfp","Vector Compare Equal To Floating-Point"},
  {"stdux","Store Doubleword with Update Indexed"},
  {"vupklpx","Vector Unpack Low Pixel"},
  {"xsrdpic","VSX Scalar Round Double-Precision to Integral using Current rounding mode"},
  {"e_rlw","Rotate Left Word"},
  {"cmpeqb","Compare Equal Byte"},
  {"xvrspim","VSX Vector Round Single-Precision to Integral toward -Infinity"},
  {"stdbrx","Store Doubleword Byte-Reverse Indexed"},
  {"sthbrx","Store Halfword Byte-Reverse Indexed"},
  {"vnand","Vector NAND"},
  {"se_rfgi","Return From Guest Interrupt"},
  {"fcmpu","Floating Compare Unordered"},
  {"stqcx.","Store Quadword Conditional Indexed & record"},
  {"cmpwi","Compare Word Immediate"},
  {"xsrdpim","VSX Scalar Round Double-Precision to Integral toward -Infinity"},
  {"mfmsr","Move From MSR"},
  {"xsrdpip","VSX Scalar Round Double-Precision to Integral toward +Infinity"},
  {"mullwo","Multiply Low Word"},
  {"fcmpo","Floating Compare Ordered"},
  {"vcmpgtuw.","Vector Compare Greater Than Unsigned Word"},
  {"xsrdpiz","VSX Scalar Round Double-Precision to Integral toward Zero"},
  {"srad.","Shift Right Algebraic Doubleword"},
  {"lhzux","Load Halfword & Zero with Update Indexed"},
  {"stfdux","Store Floating Double with Update Indexed"},
  {"xscmpodp","VSX Scalar Compare Ordered Double-Precision"},
  {"trechkpt.","Transaction Recheckpoint & record"},
  {"vpkshss","Vector Pack Signed Halfword Signed Saturate"},
  {"e_sthu","Store Halfword with Update"},
  {"vmulosw","Vector Multiply Odd Signed Word"},
  {"xxinsertw","VSX Vector Insert Word"},
  {"e_srwi.","Shift Right Word Immediate"},
  {"lwaux","Load Word Algebraic with Update Indexed"},
  {"subf.","Subtract From"},
  {"xscvdpspn","VSX Scalar Convert Double-Precision to Single-Precision Non-signalling format"},
  {"xsnmaddqpo","VSX Scalar Negative Multiply-Add Quad-Precision [with round to Odd]"},
  {"vmulosh","Vector Multiply Odd Signed Halfword"},
  {"crnand","CR NAND"},
  {"vmrghb","Vector Merge High Byte"},
  {"nand","NAND"},
  {"vrfin","Vector Round to Floating-Point Integral Nearest"},
  {"vmulosb","Vector Multiply Odd Signed Byte"},
  {"xvxsigdp","VSX Vector Extract Significand Double-Precision"},
  {"vrfim","Vector Round to Floating-Point Integral toward -Infinity"},
  {"vadduws","Vector Add Unsigned Word Saturate"},
  {"denbcdq","DFP Encode BCD To DPD Quad"},
  {"e_add16i","Add Immediate"},
  {"vmrghh","Vector Merge High Halfword"},
  {"stxvl","Store VSX Vector with Length"},
  {"xvcvspuxds","VSX Vector Convert with round to zero Single-Precision to Unsigned Doubleword format"},
  {"tsr.","Transaction Suspend or Resume & record"},
  {"se_li","Load Immediate Short Form; se_li r3, 1; r3 = 1"},
  {"vextuwrx","Vector Extract Unsigned Word Right-Indexed"},
  {"mtvscr","Move To VSCR"},
  {"vctsxs","Vector Convert with round to zero FP To Signed Word format Saturate"},
  {"nego.","Negate"},
  {"vmrghw","Vector Merge High Word"},
  {"dtstsfiq","DFP Test Significance Immediate Quad"},
  {"xvcvsphp","VSX Vector Convert with round Single-Precision to Half-Precision format"},
  {"eqv","Equivalent"},
  {"vcmpneb","Vector Compare Not Equal Byte"},
  {"xvnmaddadp","VSX Vector Negative Multiply-Add Type-A Double-Precision"},
  {"vrfiz","Vector Round to Floating-Point Integral toward Zero"},
  {"e_and2i.","AND (two operand) Immediate"},
  {"stwat","Store Word ATomic"},
  {"se_addi","Add Immediate Short Form"},
  {"dxex.","DFP Extract Exponent"},
  {"stswi","Store String Word Immediate"},
  {"addeo","Add Extended"},
  {"e_addi","Add Scaled Immediate"},
  {"e_rlwi","Rotate Left Word Immediate"},
  {"lfsx","Load Floating Single Indexed"},
  {"e_bl","Branch and Link"},
  {"stxvx","Store VSX Vector Indexed"},
  {"mullw.","Multiply Low Word"},
  {"vcmpneh","Vector Compare Not Equal Halfword"},
  {"vsubsbs","Vector Subtract Signed Byte Saturate"},
  {"vrfip","Vector Round to Floating-Point Integral toward +Infinity"},
  {"vadduwm","Vector Add Unsigned Word Modulo"},
  {"xsdivdp","VSX Scalar Divide Double-Precision"},
  {"lfsu","Load Floating Single with Update"},
  {"vcmpnew","Vector Compare Not Equal Word"},
  {"lbzux","Load Byte & Zero with Update Indexed"},
  {"vadduhm","Vector Add Unsigned Halfword Modulo"},
  {"e_crnor","Condition Register NOR"},
  {"vctzw","Vector Count Trailing Zeros Word"},
  {"addex","Add Extended using alternate carry"},
  {"vpmsumd","Vector Polynomial Multiply-Sum Doubleword"},
  {"e_bc","Branch Conditional"},
  {"stswx","Store String Word Indexed"},
  {"denbcd.","DFP Encode BCD To DPD"},
  {"stxvd2x","Store VSX Vector Doubleword*2 Indexed"},
  {"xsnegdp","VSX Scalar Negate Double-Precision"},
  {"bcctrl","Branch Conditional to CTR [& Link]"},
  {"vpmsumb","Vector Polynomial Multiply-Sum Byte"},
  {"xscvqpudz","VSX Scalar Convert with round to zero Quad-Precision to Unsigned Doubleword format"},
  {"rldic.","Rotate Left Doubleword Immediate then Clear"},
  {"vpkshus","Vector Pack Signed Halfword Unsigned Saturate"},
  {"subfe","Subtract From Extended"},
  {"vextuhlx","Vector Extract Unsigned Halfword Left-Indexed"},
  {"xoris","XOR Immediate Shifted"},
  {"vctzh","Vector Count Trailing Zeros Halfword"},
  {"se_srawi","Shift Right Algebraic Immediate"},
  {"xxlandc","VSX Vector Logical AND with Complement"},
  {"vpmsumh","Vector Polynomial Multiply-Sum Halfword"},
  {"subfc","Subtract From Carrying"},
  {"stbu","Store Byte with Update"},
  {"vorc","Vector OR with Complement"},
  {"cntlzd.","Count Leading Zeros Doubleword"},
  {"vctzd","Vector Count Trailing Zeros Doubleword"},
  {"subfo","Subtract From"},
  {"stbx","Store Byte Indexed"},
  {"vctzb","Vector Count Trailing Zeros Byte"},
  {"vpmsumw","Vector Polynomial Multiply-Sum Word"},
  {"vextractd","Vector Extract Doubleword"},
  {"cmprb","Compare Ranged Byte"},
  {"xscvqpswz","VSX Scalar Convert with round to zero Quad-Precision to Signed Word format"},
  {"dmul.","DFP Multiply"},
  {"vadduhs","Vector Add Unsigned Halfword Saturate"},
  {"se_rfi","Return From Interrupt"},
  {"fmsubs","Floating Multiply-Subtract Single"},
  {"se_bseti","Bit Set Immediate"},
  {"xvxexpsp","VSX Vector Extract Exponent Single-Precision"},
  {"subfco","Subtract From Carrying"},
  {"rlwimi.","Rotate Left Word Immediate then Mask Insert"},
  {"xsnmsubqp","VSX Scalar Negative Multiply-Subtract Quad-Precision [with round to Odd]"},
  {"subfe.","Subtract From Extended"},
  {"xscmpuqp","VSX Scalar Compare Unordered Quad-Precision"},
  {"vextsw2d","Vector Extend Sign Word to Doubleword"},
  {"vpksdus","Vector Pack Signed Doubleword Unsigned Saturate"},
  {"lhbrx","Load Halfword Byte-Reverse Indexed"},
  {"xvabsdp","VSX Vector Absolute Double-Precision"},
  {"e_stmw","Store Multiple Word"},
  {"lwzcix","Load Word & Zero Caching Inhibited Indexed"},
  {"xxlnand","VSX Vector Logical NAND"},
  {"rfid","Return from Interrupt Doubleword"},
  {"se_sub","Subtract"},
  {"e_rlw.","Rotate Left Word"},
  {"fsqrt","Floating Square Root"},
  {"eieio","Enforce In-order Execution of I/O"},
  {"srwi","Shift Right Word Immedate"},
  {"sthcix","Store Halfword Caching Inhibited Indexed"},
  {"tcheck","Transaction Check & record"},
  {"se_btsti","Bit Test Immediate"},
  {"rldicr","Rotate Left Doubleword Immediate then Clear Right"},
  {"adde.","Add Extended"},
  {"vadduqm","Vector Add Unsigned Quadword Modulo"},
  {"cdtbcd","Convert Declets To Binary Coded Decimal"},
  {"lvxl","Load Vector Indexed Last"},
  {"vcmpbfp","Vector Compare Bounds Floating-Point"},
  {"e_or2i","OR (two operand) Immediate"},
  {"dxexq","DFP Extract Exponent Quad"},
  {"tdi","Trap Doubleword Immediate"},
  {"vandc","Vector Logical AND with Complement"},
  {"dmulq","DFP Multiply Quad"},
  {"fnmsub","Floating Negative Multiply-Subtract"},
  {"e_mcrf","Move CR Field"},
  {"xscvsxdsp","VSX Scalar Convert with round Signed Doubleword to Single-Precision format"},
  {"dquai.","DFP Quantize Immediate"},
  {"fmsub.","Floating Multiply-Subtract"},
  {"se_bmaski","Bit Mask Generate Immediate"},
  {"xvnegdp","VSX Vector Negate Double-Precision"},
  {"xssqrtqpo","VSX Scalar Square Root Quad-Precision [with round to Odd]"},
  {"rldicl","Rotate Left Doubleword Immediate then Clear Left"},
  {"xvcmpgedp.","VSX Vector Compare Greater Than or Equal Double-Precision"},
  {"mftb","Move From Time Base"},
  {"addco.","Add Carrying"},
  {"vextsb2w","Vector Extend Sign Byte to Word"},
  {"e_and2is","AND (2 operand) Immediate Shifted"},
  {"xvcvuxwsp","VSX Vector Convert with round Unsigned Word to Single-Precision format"},
  {"subfeo.","Subtract From Extended"},
  {"ldbrx","Load Doubleword Byte-Reverse Indexed"},
  {"andis.","AND Immediate Shifted & record"},
  {"fcfidus.","Floating Convert with round Unsigned Doubleword to Single-Precision format"},
  {"stxsd","Store VSX Scalar Doubleword"},
  {"lfsux","Load Floating Single with Update Indexed"},
  {"fabs","Floating Absolute"},
  {"se_bctr","Branch to Count Register"},
  {"frin.","Floating Round To Integer Nearest"},
  {"xssqrtdp","VSX Scalar Square Root Double-Precision"},
  {"vextsb2d","Vector Extend Sign Byte to Doubleword"},
  {"vpermxor","Vector Permute & Exclusive-OR"},
  {"xxland","VSX Vector Logical AND"},
  {"xstdivdp","VSX Scalar Test for software Divide Double-Precision"},
  {"vmrglb","Vector Merge Low Byte"},
  {"subfc.","Subtract From Carrying"},
  {"se_subi.","Subtract Immediate"},
  {"subfeo","Subtract From Extended"},
  {"dcmpu","DFP Compare Unordered"},
  {"xnop","Executed No Operation"},
  {"e_stw","Store Word"},
  {"dcmpo","DFP Compare Ordered"},
  {"e_sth","Store Halfword"},
  {"vmrglh","Vector Merge Low Halfword"},
  {"vmrglw","Vector Merge Low Word"},
  {"bcctr","Branch Conditional to CTR [& Link]"},
  {"xscvuxdsp","VSX Scalar Convert with round Unsigned Doubleword to Single-Precision format"},
  {"vupklsb","Vector Unpack Low Signed Byte"},
  {"xvcvspdp","VSX Vector Convert Single-Precision to Double-Precision format"},
  {"e_stb","Store Byte"},
  {"fadd.","Floating Add"},
  {"ddiv","DFP Divide"},
  {"srw.","Shift Right Word"},
  {"lwarx","Load Word & Reserve Indexed"},
  {"fneg.","Floating Negate"},
  {"lfdpx","Load Floating Double Pair Indexed"},
  {"xvsubsp","VSX Vector Subtract Single-Precision"},
  {"se_blr","Branch to Link Register"},
  {"vcipherlast","Vector AES Cipher Last"},
  {"frim.","Floating Round To Integer Minus"},
  {"se_subi","Subtract Immediate"},
  {"sradi.","Shift Right Algebraic Doubleword Immediate"},
  {"vupklsh","Vector Unpack Low Signed Halfword"},
  {"stfd","Store Floating Double"},
  {"vcmpequw.","Vector Compare Equal To Unsigned Word"},
  {"rldimi","Rotate Left Doubleword Immediate then Mask Insert"},
  {"frsp","Floating Round to Single-Precision"},
  {"divdeu","Divide Doubleword Extended Unsigned"},
  {"xvcvdpuxds","VSX Vector Convert with round to zero Double-Precision to Unsigned Doubleword format"},
  {"xor.","XOR"},
  {"se_subf","Subtract From Short Form"},
  {"vupklsw","Vector Unpack Low Signed Word"},
  {"xvcmpeqsp.","VSX Vector Compare Equal Single-Precision"},
  {"divdeo","Divide Doubleword Extended"},
  {"bcdcfn.","Decimal Convert From National & record"},
  {"tlbsync","TLB Synchronize"},
  {"lbzu","Load Byte & Zero with Update"},
  {"vmulouw","Vector Multiply Odd Unsigned Word"},
  {"se_or","OR Short Form"},
  {"slwi","Shift Left Word Immediate"},
  {"xvnmsubmdp","VSX Vector Negative Multiply-Subtract Type-M Double-Precision"},
  {"xscvqpdp","VSX Scalar Convert with round Quad-Precision to Double-Precision format [with round to Odd]"},
  {"xxsel","VSX Vector Select"},
  {"stfs","Store Floating Single"},
  {"dxexq.","DFP Extract Exponent Quad"},
  {"lbzx","Load Byte & Zero Indexed"},
  {"vsum4shs","Vector Sum across Quarter Signed Halfword Saturate"},
  {"bcdutrunc.","Decimal Unsigned Truncate & record"},
  {"vaddecuq","Vector Add Extended & write Carry Unsigned Quadword"},
  {"vsubeuqm","Vector Subtract Extended Unsigned Quadword Modulo"},
  {"e_stbu","Store Byte with Update"},
  {"xvcvhpsp","VSX Vector Convert Half-Precision to Single-Precision format"},
  {"mcrf","Move CR Field"},
  {"stvebx","Store Vector Element Byte Indexed"},
  {"vmulouh","Vector Multiply Odd Unsigned Halfword"},
  {"se_mtar","Move To Alternate Register"},
  {"xvnmaddmdp","VSX Vector Negative Multiply-Add Type-M Double-Precision"},
  {"se_lbz","Load Byte and Zero Short Form"},
  {"extsh.","Extend Sign Halfword"},
  {"vcmpnezw.","Vector Compare Not Equal or Zero Word"},
  {"vcmpneb.","Vector Compare Not Equal Byte"},
  {"dquaiq","DFP Quantize Immediate Quad"},
  {"xsmaddqpo","VSX Scalar Multiply-Add Quad-Precision [with round to Odd]"},
  {"vor","Vector Logical OR"},
  {"fmrgow","Floating Merge Odd Word"},
  {"vmuloub","Vector Multiply Odd Unsigned Byte"},
  {"vextuwlx","Vector Extract Unsigned Word Left-Indexed"},
  {"xvcvdpsp","VSX Vector Convert with round Double-Precision to Single-Precision format"},
  {"stxsibx","Store VSX Scalar as Integer Byte Indexed"},
  {"vinsertd","Vector Insert Doubleword"},
  {"xvnmsubadp","VSX Vector Negative Multiply-Subtract Type-A Double-Precision"},
  {"bctarl","Branch Conditional to BTAR [& Link]"},
  {"xscvspdpn","VSX Scalar Convert Single-Precision to Double-Precision Non-signalling format"},
  {"vinsertb","Vector Insert Byte"},
  {"xsmsubmdp","VSX Scalar Multiply-Subtract Type-M Double-Precision"},
  {"vinserth","Vector Insert Halfword"},
  {"e_and2is.","AND (2 operand) Immediate Shifted"},
  {"fadds","Floating Add Single"},
  {"mulldo.","Multiply Low Doubleword"},
  {"xssubqpo","VSX Scalar Subtract Quad-Precision [with round to Odd]"},
  {"stxvw4x","Store VSX Vector Word*4 Indexed"},
  {"vinsertw","Vector Insert Word"},
  {"cmpw","Compare Word; cmpw CR0, r0, r1 (signed)"},
  {"xori","XOR Immediate"},
  {"wait","Wait for Interrupt"},
  {"xsmindp","VSX Scalar Minimum Double-Precision"},
  {"cmpi","Compare Immediate"},
  {"xsnmsubadp","VSX Scalar Negative Multiply-Subtract Type-A Double-Precision"},
  {"xxperm","VSX Vector Permute"},
  {"cmpl","Compare Logical"},
  {"vpkpx","Vector Pack Pixel"},
  {"tabort.","Transaction Abort & record"},
  {"divde.","Divide Doubleword Extended"},
  {"vmrgow","Vector Merge Odd Word"},
  {"xvmaddasp","VSX Vector Multiply-Add Type-A Single-Precision"},
  {"cmpb","Compare Byte"},
  {"slw.","Shift Left Word"},
  {"fsel","Floating Select"},
  {"stvehx","Store Vector Element Halfword Indexed"},
  {"se_mr","Move Register"},
  {"rldcr.","Rotate Left Doubleword then Clear Right"},
  {"xscmpgedp","VSX Scalar Compare Greater Than or Equal Double-Precision"},
  {"lxvw4x","Load VSX Vector Word*4 Indexed"},
  {"dmulq.","DFP Multiply Quad"},
  {"stfsu","Store Floating Single with Update"},
  {"xscvhpdp","VSX Scalar Convert Half-Precision to Double-Precision format"},
  {"e_slwi","Shift Left Word Immediate"},
  {"vextublx","Vector Extract Unsigned Byte Left-Indexed"},
  {"xsabsqp","VSX Scalar Absolute Quad-Precision"},
  {"vsraw","Vector Shift Right Algebraic Word"},
  {"bcds.","Decimal Shift & record"},
  {"subfo.","Subtract From"},
  {"fres.","Floating Reciprocal Estimate Single"},
  {"setb","Set Boolean"},
  {"vsum4sbs","Vector Sum across Quarter Signed Byte Saturate"},
  {"cnttzw","Count Trailing Zeros Word"},
  {"se_srw","Shift Right Word"},
  {"stfsx","Store Floating Single Indexed"},
  {"xssqrtsp","VSX Scalar Square Root Single-Precision"},
  {"e_cmpi","Compare Scaled Immediate Word"},
  {"e_cmph","Compare Halfword"},
  {"vsrab","Vector Shift Right Algebraic Byte"},
  {"se_mflr","Move From Link Register"},
  {"vsrad","Vector Shift Right Algebraic Doubleword"},
  {"xviexpsp","VSX Vector Insert Exponent Single-Precision"},
  {"e_cmphl16i","Compare Halfword Logical Immediate"},
  {"vpksdss","Vector Pack Signed Doubleword Signed Saturate"},
  {"vsrah","Vector Shift Right Algebraic Halfword"},
  {"cnttzd","Count Trailing Zeros Doubleword"},
  {"subfzeo.","Subtract From Zero Extended"},
  {"addc.","Add Carrying"},
  {"addme","Add to Minus One Extended"},
  {"xvcmpgesp.","VSX Vector Compare Greater Than or Equal Single-Precision"},
  {"xsdivqpo","VSX Scalar Divide Quad-Precision [with round to Odd]"},
  {"ldux","Load Doubleword with Update Indexed"},
  {"mcrfs","Move To CR from FPSCR"},
  {"xscvdpuxws","VSX Scalar Convert with round to zero Double-Precision to Unsigned Word format"},
  {"e_crnand","Condition Register NAND"},
  {"xvtsqrtsp","VSX Vector Test for software Square Root Single-Precision"},
  {"bcdsetsgn.","Decimal Set Sign & record"},
  {"fctidz.","Floating Convert with round to Zero Double-Precision To Signed Doubleword format"},
  {"se_sth","Store Halfword Short Form"},
  {"vrlwnm","Vector Rotate Left Word then AND with Mask"},
  {"drsp.","DFP Round To DFP Short"},
  {"e_ori.","OR Scaled Immediate"},
  {"vctzlsbb","Vector Count Trailing Zero Least-Significant Bits Byte"},
  {"se_stb","Store Byte Short Form"},
  {"divdeuo","Divide Doubleword Extended Unsigned"},
  {"bdzt","Decrement CTR and Branch if its Zero (true)"},
  {"extrwi","Extract and Right Justify Immediate"},
  {"tabortdci.","Transaction Abort Doubleword Conditional Immediate & record"},
  {"lfdux","Load Floating Double with Update Indexed"},
  {"subfmeo.","Subtract From Minus One Extended"},
  {"se_mfctr","Move From Count Register"},
  {"stxsspx","Store VSX Scalar Single-Precision Indexed"},
  {"xvdivsp","VSX Vector Divide Single-Precision"},
  {"vmladduhm","Vector Multiply-Low-Add Unsigned Halfword Modulo"},
  {"xvcmpeqsp","VSX Vector Compare Equal Single-Precision"},
  {"se_stw","Store Word Short Form"},
  {"bdzf","Decrement CTR and Branch if its Zero (false)"},
  {"drdpq","DFP Round To DFP Long"},
  {"mulhdu.","Multiply High Doubleword Unsigned"},
  {"mtfsfi.","Move To FPSCR Field Immediate"},
  {"addzeo.","Add to Zero Extended"},
  {"xxsldwi","VSX Vector Shift Left Double by Word Immediate"},
  {"se_neg","Negate Short Form"},
  {"stbcx.","Store Byte Conditional Indexed & record"},
  {"addco","Add Carrying"},
  {"rldcl.","Rotate Left Doubleword then Clear Left"},
  {"vsububm","Vector Subtract Unsigned Byte Modulo"},
  {"fctiwz.","Floating Convert with round to Zero Double-Precision To Signed Word format"},
  {"fcfids","Floating Convert with round Signed Doubleword to Single-Precision format"},
  {"xvcvspsxds","VSX Vector Convert with round to zero Single-Precision to Signed Doubleword format"},
  {"vsububs","Vector Subtract Unsigned Byte Saturate"},
  {"fcfidu","Floating Convert with round Unsigned Doubleword to Double-Precision format"},
  {"dctqpq.","DFP Convert To DFP Extended"},
  {"xscmpexpqp","VSX Scalar Compare Exponents Quad-Precision"},
  {"stfsux","Store Floating Single with Update Indexed"},
  {"vsubshs","Vector Subtract Signed Halfword Saturate"},
  {"vsubsws","Vector Subtract Signed Word Saturate"},
  {"msgclrp","Message Clear Privileged"},
  {"xstsqrtdp","VSX Scalar Test for software Square Root Double-Precision"},
  {"xxleqv","VSX Vector Logical Equivalence"},
  {"stdu","Store Doubleword with Update"},
  {"cmplw","Compare Logical Word; cmplwi CR0, r0, 33(unsigned)"},
  {"lswi","Load String Word Immediate"},
  {"divdeu.","Divide Doubleword Extended Unsigned"},
  {"xxlxor","VSX Vector Logical XOR"},
  {"vcmpgtsh.","Vector Compare Greater Than Signed Halfword"},
  {"extsb.","Extend Sign Byte"},
  {"stdx","Store Doubleword Indexed"},
  {"vclzlsbb","Vector Count Leading Zero Least-Significant Bits Byte"},
  {"xscvqpuwz","VSX Scalar Convert with round to zero Quad-Precision to Unsigned Word format"},
  {"dquaq.","DFP Quantize Quad"},
  {"lswx","Load String Word Indexed"},
  {"xsmsubadp","VSX Scalar Multiply-Subtract Type-A Double-Precision"},
  {"vsplth","Vector Splat Halfword"},
  {"lvewx","Load Vector Element Word Indexed"},
  {"se_and.","AND Short Form"},
  {"vbpermq","Vector Bit Permute Quadword"},
  {"subfme","Subtract From Minus One Extended"},
  {"fcfid.","Floating Convert with round Signed Doubleword to Double-Precision format"},
  {"fmrgew","Floating Merge Even Word"},
  {"e_bcl","Branch Conditional and Link"},
  {"rldicr.","Rotate Left Doubleword Immediate then Clear Right"},
  {"vspltb","Vector Splat Byte"},
  {"divwuo.","Divide Word Unsigned"},
  {"cmpli","Compare Logical Immediate"},
  {"xvxexpdp","VSX Vector Extract Exponent Double-Precision"},
  {"addo.","Add"},
  {"xvsqrtsp","VSX Vector Square Root Single-Precision"},
  {"xvxsigsp","VSX Vector Extract Significand Single-Precision"},
  {"xsnmsubmdp","VSX Scalar Negative Multiply-Subtract Type-M Double-Precision"},
  {"xvmsubadp","VSX Vector Multiply-Subtract Type-A Double-Precision"},
  {"addic","Add Immediate Carrying and Record ; addic r3, r3, 1"},
  {"vbpermd","Vector Bit Permute Doubleword"},
  {"stop","Stop"},
  {"xxextractuw","VSX Vector Extract Unsigned Word"},
  {"xststdcdp","VSX Scalar Test Data Class Double-Precision"},
  {"vspltw","Vector Splat Word"},
  {"fadd","Floating Add"},
  {"rfscv","Return From System Call Vectored"},
  {"vsubfp","Vector Subtract Floating-Point"},
  {"fctiwz","Floating Convert with round to Zero Double-Precision To Signed Word format"},
  {"addis","Add Immediate Shifted"},
  {"se_not","NOT Short Form"},
  {"bcla","Branch Conditional [& Link] [Absolute]"},
  {"rfebb","Return from Event Based Branch"},
  {"darn","Deliver A Random Number"},
  {"xvmsubmdp","VSX Vector Multiply-Subtract Type-M Double-Precision"},
  {"lvsl","Load Vector for Shift Left"},
  {NULL, NULL}
};


typedef int (*GperfForeachCallback)(void *user, const char *k, const char *v);
int gperf_ppc_foreach(GperfForeachCallback cb, void *user) {
  int i = 0; while (kvs[i].name) {
  cb (user, kvs[i].name, kvs[i].value);
  i++;}
  return 0;
}
const char *gperf_ppc_get(const char *s) {
  int i = 0; while (kvs[i].name) {
  if (!strcmp (s, kvs[i].name)) return kvs[i].value;
  i++;}
  return NULL;
}
#define sdb_hash_c_ppc(x,y) gperf_ppc_hash(x)
const unsigned int gperf_ppc_hash(const char *s) {
  int sum = strlen (s);
  while (*s) { sum += *s; s++; }
  return sum;
}
struct {const char *name;void *get;void *hash;void *foreach;} gperf_ppc = {
  .name = "ppc",
  .get = &gperf_ppc_get,
  .hash = &gperf_ppc_hash,
  .foreach = &gperf_ppc_foreach
};

#if MAIN
int main () {
 const char *s = ((char*(*)(char*))gperf_ppc.get)("foo");
 printf ("%s\n", s);
}
#endif
